{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Here is my attempt to use Tensorflow for this dataset using the kagglegym API. The notebook is still under construction.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Kagglegym import...",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import kagglegym\n# Create environment\nenv = kagglegym.make()\n# Get first observation\nobservation = env.reset()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "One major problem of this dataset is the number of missing values. First, we want to make sure that there is enough complete data to learn something meaningful.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "observation.train.dropna().shape",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for col in observation.train.columns:\n    print(col)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Analyze of the output to design the network output.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "observation.train[\"y\"].hist(bins=100)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "observation.train.dropna()[\"technical_5\"].hist(bins=100)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The output seems to have a zero mean making sense to take a sigmoid as an output.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import tensorflow as tf\nprint(tf.__version__)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Simple two layer neural net minimizing the mean squared value. I am trying to switch to R2 loss later (see my attempt in the code)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import tensorflow.contrib.layers as layers\nimport tensorflow.contrib.losses as losses\n\nN_FEATURES=108\nLEARNING_RATE = 0.001\n\nx = tf.placeholder(tf.float32, shape=(None, N_FEATURES))\ny = tf.placeholder(tf.float32, shape=(None,1))\np = tf.placeholder(tf.float32)\nlogits = layers.fully_connected(x, 56, activation_fn=tf.nn.relu)\nlogits = layers.dropout(logits, keep_prob=p)\nlogits = layers.fully_connected(x, 56, activation_fn=tf.nn.relu)\nlogits = layers.dropout(logits, keep_prob=p)\ny_ = layers.fully_connected(logits, 1)\n\nloss = losses.mean_squared_error(y, y_)\n\n# loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-y_)) / tf.square(y_ - tf.reduce_mean(y_))) # Equivalent to minimize R2\n\ntrain_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Numpy arrays for feeding the network. Splitting into train and test sets.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.cross_validation import train_test_split\ntraindf, testdf = train_test_split(observation.train.drop(axis=1, labels=[\"id\", \"timestamp\"]).dropna(),\n                                  train_size=0.8,\n                                  test_size=0.2)\n\nY_train = traindf[\"y\"]\nX_train = traindf.drop(axis=1, labels=[\"y\"])\n\nY_test = testdf[\"y\"]\nX_test = testdf.drop(axis=1, labels=[\"y\"])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Training process by batch.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "num_examples = X_train.shape[0]\nbatch_size = 32\nn_epoch = 2\nn_batch = int(num_examples / batch_size)\nprint(\"Feeding {} batches per epoch\".format(n_batch))\nstart = 0\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n\nfor _ in range(n_epoch):\n    start = 0\n    for batch_idx in range(n_batch-1):\n    #for batch_idx in range(15):\n        feeding_dict = { x: X_train.iloc[start:(start+batch_size)].values,\n                        y: Y_train.iloc[start:(start+batch_size)].values.reshape(-1, 1),\n                       p:0.5}\n        start+=batch_size\n\n        _, l  = sess.run([train_op, loss], feed_dict=feeding_dict)\n\n        if not(batch_idx%1000):\n            print(\"Loss on batch {}: {}\".format(batch_idx, l))\n    ",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import tensorflow.contrib.metrics as metrics\n\nsmse, smse_update_op = metrics.streaming_mean_squared_error(y, y_)\n\nnum_examples = X_test.shape[0]\nbatch_size = 32\nn_batch = int(num_examples / batch_size)\nprint(\"Feeding {} batches per epoch\".format(n_batch))\nstart = 0\n\nsess.run(tf.initialize_local_variables())\n\nfor batch_idx in range(n_batch-1):\n    feeding_dict = { x: X_test.iloc[start:(start+batch_size)].values,\n    y: Y_test.iloc[start:(start+batch_size)].values.reshape(-1, 1),\n                   p:1.}\n    start+=batch_size\n    sess.run(smse_update_op, feed_dict=feeding_dict)\nprint(\"Total loss: {}\".format(sess.run(smse)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}