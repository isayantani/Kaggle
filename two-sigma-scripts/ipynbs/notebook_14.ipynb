{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "I found kagglegym_emulation to be very helpfull (https://www.kaggle.com/slothouber/two-sigma-financial-modeling/kagglegym-emulation). What this script does is validating it against the actual kagglegym. I used some snippets from this script https://www.kaggle.com/sankhamukherjee/two-sigma-financial-modeling/prediction-model-elastic-net. \n\nVote up if you find it meaningful :)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import ElasticNetCV\nimport kagglegym\nimport math",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# kagglegym_emulation code\ndef r_score(y_true, y_pred):\n    r2 = r2_score(y_true, y_pred)\n    r = np.sign(r2) * np.sqrt(np.abs(r2))\n    return max(-1, r)\n\n\nclass Observation(object):\n    def __init__(self, train, target, features):\n        self.train = train\n        self.target = target\n        self.features = features\n\n\nclass Environment(object):\n    def __init__(self):\n        with pd.HDFStore(\"../input/train.h5\", \"r\") as hfdata:\n            self.timestamp = 0\n            fullset = hfdata.get(\"train\")\n            self.unique_timestamp = fullset[\"timestamp\"].unique()\n            # Get a list of unique timestamps\n            # use the first half for training and\n            # the second half for the test set\n            n = len(self.unique_timestamp)\n            i = int(n/2)\n            timesplit = self.unique_timestamp[i]\n            self.n = n\n            self.unique_idx = i\n            self.train = fullset[fullset.timestamp < timesplit]\n            self.test = fullset[fullset.timestamp >= timesplit]\n\n            # Needed to compute final score\n            self.full = self.test.loc[:, ['timestamp', 'y']]\n            self.full['y_hat'] = 0.0\n            self.temp_test_y = None\n\n    def reset(self):\n        timesplit = self.unique_timestamp[self.unique_idx]\n\n        self.unique_idx = int(self.n / 2)\n        self.unique_idx += 1\n        subset = self.test[self.test.timestamp == timesplit]\n\n        # reset index to conform to how kagglegym works\n        target = subset.loc[:, ['id', 'y']].reset_index(drop=True)\n        self.temp_test_y = target['y']\n\n        target.loc[:, 'y'] = 0.0  # set the prediction column to zero\n\n        # changed bounds to 0:110 from 1:111 to mimic the behavior\n        # of api for feature\n        features = subset.iloc[:, :110].reset_index(drop=True)\n\n        observation = Observation(self.train, target, features)\n        return observation\n\n    def step(self, target):\n        timesplit = self.unique_timestamp[self.unique_idx-1]\n        # Since full and target have a different index we need\n        # to do a _values trick here to get the assignment working\n        y_hat = target.loc[:, ['y']]\n        self.full.loc[self.full.timestamp == timesplit, ['y_hat']] = y_hat._values\n\n        if self.unique_idx == self.n:\n            done = True\n            observation = None\n            reward = r_score(self.temp_test_y, target.loc[:, 'y'])\n            score = r_score(self.full['y'], self.full['y_hat'])\n            info = {'public_score': score}\n        else:\n            reward = r_score(self.temp_test_y, target.loc[:, 'y'])\n            done = False\n            info = {}\n            timesplit = self.unique_timestamp[self.unique_idx]\n            self.unique_idx += 1\n            subset = self.test[self.test.timestamp == timesplit]\n\n            # reset index to conform to how kagglegym works\n            target = subset.loc[:, ['id', 'y']].reset_index(drop=True)\n            self.temp_test_y = target['y']\n\n            # set the prediction column to zero\n            target.loc[:, 'y'] = 0\n\n            # column bound change on the subset\n            # reset index to conform to how kagglegym works\n            features = subset.iloc[:, 0:110].reset_index(drop=True)\n\n            observation = Observation(self.train, target, features)\n\n        return observation, reward, done, info\n\n    def __str__(self):\n        return \"Environment()\"\n\n\ndef make():\n    return Environment()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# predictive model wrapper, also see https://www.kaggle.com/sankhamukherjee/two-sigma-financial-modeling/prediction-model-elastic-net\nclass fitModel():\n    def __init__(self, model, train, columns):\n\n        # first save the model ...\n        self.model   = model\n        self.columns = columns\n        \n        # Get the X, and y values, \n        y = np.array(train.y)\n        \n        X = train[columns]\n        self.xMeans = X.mean(axis=0) # Remember to save this value\n        self.xStd   = X.std(axis=0)  # Remember to save this value\n\n        X = np.array(X.fillna( self.xMeans ))\n        X = (X - np.array(self.xMeans))/np.array(self.xStd)\n        \n        # fit the model\n        self.model.fit(X, y)\n        \n        return\n    \n    def predict(self, features):\n        X = features[self.columns]\n        X = np.array(X.fillna( self.xMeans ))\n        X = (X - np.array(self.xMeans))/np.array(self.xStd)\n\n        return self.model.predict(X)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def list_match(list_a, list_b):\n    for i, j in zip(list_a, list_b):\n        if i != j:\n            return False\n    return True",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Validaiton of kagglegym_emulation\nenv = kagglegym.make()\nenv_test = make()\n\n# Check observations\nobservation = env.reset()\nobservation_test = env_test.reset()\nassert list_match(observation.train.id.values, observation_test.train.id.values)    \n    \nelastic_net = ElasticNetCV()\ncolumns = ['technical_30', 'technical_20', 'fundamental_11', 'technical_19']\nmodel = fitModel(elastic_net, observation.train.copy(), columns)\nmodel_test = fitModel(elastic_net, observation_test.train.copy(), columns)\n\nwhile True:\n        \n    prediction       = model.predict(observation.features.copy())\n    prediction_test  = model_test.predict(observation_test.features.copy())\n    \n    assert list_match(prediction, prediction_test)\n  \n    \n    target           = observation.target\n    target_test      = observation_test.target\n    target['y'] = prediction\n    target_test['y'] = prediction_test\n        \n    timestamp = observation.features[\"timestamp\"][0]\n    if timestamp % 100 == 0:\n        print(timestamp)\n    \n    observation, reward, done, info = env.step(target)\n    observation_test, reward_test, done_test, info_test = env_test.step(target)\n    \n\n    assert done == done_test\n    assert math.isclose(reward, reward_test, abs_tol=5e-05)\n    \n\n    if done: \n        assert math.isclose(info['public_score'],info_test['public_score'],  abs_tol=1e-07)\n        print('Info:',info['public_score'],'Info-test:',info_test['public_score'])\n        break",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**VALIDATED SUCCESSFULLY !!!**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}