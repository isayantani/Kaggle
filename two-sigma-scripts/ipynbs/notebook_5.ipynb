{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "I have found that the proportion of new asserts in the test set is higher than in the train set. One of my model has improved from 0.0141 to 0.147. I could share it after the deadline. In the meantime you could find the approach in this notebook. I believe even the local score is lower than the original one by Hamed https://www.kaggle.com/pinocchio/two-sigma-financial-modeling/tensorflow-lr/run/903884 this script should give a slightly higher score in the LB. Hope you could use this information to get out of the public-script score. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import kagglegym\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing as pp\n\nenv = kagglegym.make()\no = env.reset()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "col = ['technical_20']\ntrain = o.train[col + ['id', 'timestamp', 'y']].copy(deep=True)\n\nim = pp.Imputer(strategy='median')\ntrain[col] = im.fit_transform(train[col])\nsX = pp.StandardScaler()\ntrain[col] = sX.fit_transform(train[col])\ntrain['b'] = 1\n\ny_min = train.y.min()\ny_max = train.y.max()\n\ndf_id = train[['id', 'timestamp']].groupby('id').agg([np.min])\ndf_id.reset_index(level=0, inplace=True)\ntrain = pd.merge(train, df_id, on='id', how='inner')\ntrain = train.rename(columns={train.columns[len(train.columns)-1]: 'min_ts'})\ntrain = train.loc[(train.min_ts > 1) & (train.y<y_max) & (train.y>y_min)].copy(deep=True)\n\n\nfeatures = ['b']+col\nn = len(features)\n\nlearning_rate = 0.01\ntraining_epochs = 1000\ncost_history = np.empty(shape=[1],dtype=float)\n\nX = tf.placeholder(tf.float32,[None,n])\nY = tf.placeholder(tf.float32,[None,1])\nW = tf.Variable(tf.zeros([n,1]))\n\ninit = tf.global_variables_initializer()\n\ny_ = tf.matmul(X, W)\n\ncost = tf.add(tf.reduce_mean(tf.square(y_ - Y)), tf.reduce_mean(tf.square(W)))\ntraining_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\nsess = tf.Session()\nsess.run(init)\n\nfor epoch in range(training_epochs):\n    sess.run(training_step,feed_dict={X: train[features], Y: train[['y']].values})",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "while True:\n    o.features[col] = im.transform(o.features[col])\n    o.features[col] = sX.transform(o.features[col])\n    o.features['b'] = 1\n    \n    o.target.y = sess.run(y_, feed_dict={X:o.features[features]})\n    o.target.y = np.clip(o.target.y, y_min, y_max)\n    \n    o, reward, done, info = env.step(o.target)\n    if done:\n        print(info)\n        break\n    if o.features.timestamp[0] % 100 == 0:\n        print(reward)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}