{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Cluster Id's based on correlation of NaN structure between Id\n# but first\n## All NaN are not Random Confirmation\nHypothesis :\n- From [Devin's](https://www.kaggle.com/devinanzelmo/two-sigma-financial-modeling/pandas-rolling-and-a-quick-look-at-missing-values) and [Reziproke's](https://www.kaggle.com/reziproke/two-sigma-financial-modeling/nan-structure-on-id-level-eda/notebook) analysis. Taking a look at the missing values, the first thing that pops out is that once valid values occur there are no more missing values\n\nHow to check the hypothesis?\n- Check wether there are some missing value in the middle",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\n%matplotlib inline\n\npd.set_option('display.max_columns', 120)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n    # Note that the \"train\" dataframe is the only dataframe in the file\n    df = train.get(\"train\")\n\ndf.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Change NaN to 1. and non-NaN into 0",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "features = [x for x in df.columns.values if x not in ['id','y','timestamp']]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def makeBinaryNaN(x):\n    if x == x: # if x == x is true then is not NaN, so return 0\n        return 0.\n    else: # if NaN return 1\n        return 1.\n    \ndfnan = df.applymap(makeBinaryNaN)\ndfnan['id'] = df['id']\ndfnan['timestamp'] = df['timestamp']\ndfnan.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Next, find signal that indicates that there is a change from 0 (non-NaN) to 1 (NaN) across timestamp. To do that I differentiate data with it's shifted form. The sum them. If there are more that 1 signal, it means maybe there exist NaN in the middle.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ids = dfnan['id'].unique()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_agg_signal = pd.DataFrame()\nfor id in ids:\n    df_signal = dfnan[dfnan['id'] == id][features].apply(lambda x: abs(x-x.shift()))\n    df_signal.dropna(inplace=True)\n    df_agg_signal[id] = df_signal.sum()\n\ndf_agg_signal.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "detect wether there are value > 1.0 in above dataFrame",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "listofIdwithMiddleNaN = []\n\nfor id in df_agg_signal.columns:\n    if ([True] in (df_agg_signal[id].values > 1.)):\n        listofIdwithMiddleNaN.append(theid)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "len(listofIdwithMiddleNaN)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "So all the values are 0 or 1. I cannot find double changing signal. Either NaN appers at few first row only, or all are NaN, or there is no NaN. No NaN is in the middle. So it confirms [Devin's](https://www.kaggle.com/devinanzelmo) and [Reziproke's](https://www.kaggle.com/reziproke/two-sigma-financial-modeling/nan-structure-on-id-level-eda/notebook) hypothesis that the NaN structure are not random. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Next : Cluster Id's based on correlation of NaN structure between Id\n\nAs [Reziproke's](https://www.kaggle.com/reziproke/two-sigma-financial-modeling/nan-structure-on-id-level-eda/notebook) and [lesibius's](https://www.kaggle.com/lesibius/two-sigma-financial-modeling/financial-instrument-types) analysis. Can Ids be clustered based of their NaN structure?\n\nHere I try to use NaN ratio as Reziproke and then try to cluster Id based on correlation between Id's NaN correlation",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Fist I define counter variable that would be used to help me calculate how much timestamp for each Id",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dfnan['counter'] = [1]*dfnan.shape[0]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The group our nan dataframe by id's and with summation aggregate to find how much NaN appear for each Id",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dfnan_gb = dfnan[['id']+['counter']+features].groupby('id').agg('sum')\ndfnan_gb.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Next I devide data for each column by the counter column to find relative ratio of NaN. The values are between 0 and 1. If the result is 0 then there are no NaN, but if 1 then all are NaN as follows",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_rel_nan = dfnan_gb.apply(lambda x: x/x[0], axis=1)\ndf_rel_nan.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The following is the visualization of above dataframe without the counter part",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure()\nsns.heatmap(df_rel_nan[features].as_matrix())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Next, I want calculate the correlation of NaN structure between each Id, to do that, I need to transpose the dataframe as follow",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_rel_nan_t = df_rel_nan[features].T\ndf_rel_nan_t.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Correlation of NaN structure between Id\nThen calculate the correlation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "corr = df_rel_nan_t.corr()\ncorr.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Here the cluster map visualization of the correlation matrix",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(14,14))\nsns.clustermap(corr.as_matrix())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Affinity Propagation Clustering\n\nI dont know how much cluster there, so I try to cluster the with **affinity propagation** clustering algo by which can automatically detect how much cluster that exist",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import cluster\n\n_, labels = cluster.affinity_propagation(corr.as_matrix())\nn_labels = labels.max()\nn_clusters = n_labels + 1",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Below I find the 116 clusters and their members",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Ids = df_rel_nan.index\n\nfor i in range(n_labels + 1):\n    print('Cluster {}: {}'.format((i), ', '.join( str(e) for e in list(Ids[labels == i]) )   ))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "with the size of the clusters are :",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for i in range(n_labels + 1):\n    print('Cluster {}: {}'.format((i), len(list(Ids[labels == i]))))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The optimal number of clusters base on NaN structure from **affinity propagation** algorithm are 116. But as we can see there are some big clusters :\n\n- Cluster 27: 181\n- Cluster 61: 126\n- Cluster 69: 85\n- Cluster 104: 65\n\nSo I think we can shrink them to into just 5 or 6 Cluster by using **K-Means** clustering algo as follows",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## K-Means Clustering",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.cluster import KMeans\n\nn_clusters = 5\n\nlabels_kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(corr.as_matrix())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The following are the member of those 5 clusters",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Ids = df_rel_nan.index\n\nfor i in range(n_clusters):\n    print('Cluster {}: {}'.format((i), ', '.join( str(e) for e in list(Ids[labels_kmeans == i]) )   ))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for i in range(n_clusters):\n    print('Cluster {}: {}'.format((i), len(list(Ids[labels_kmeans == i]))))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Here are the signature characteristic of each cluster",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for i in range(n_clusters):\n    Idclus = list(Ids[labels_kmeans == i])\n    dfclus = df_rel_nan[features].loc[Idclus].head()\n    stripe = dfclus.sum().values.astype(float)/dfclus.sum().values.max()\n    plt.figure(figsize = (10,0.5))\n    sns.heatmap([list(stripe)], square=True, yticklabels = False, cbar =False)\n    plt.text(7, 1.01,'Cluster {}'.format(str(i)), \n             fontsize=10, horizontalalignment='right', color='green', verticalalignment='bottom')\n    plt.text(20, 1.01,'Members : {} ...'.format(', '.join( str(e) for e in list(Ids[labels_kmeans == i])[:10] )),\n             fontsize=10, color='red', verticalalignment='bottom')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": null,
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}