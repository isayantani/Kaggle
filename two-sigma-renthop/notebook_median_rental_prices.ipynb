{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Just a little look at how prices impact interest_level",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Some useful imports",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Read data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train = pd.read_json('../input/train.json').set_index('listing_id')\ntest = pd.read_json('../input/test.json').set_index('listing_id')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Scatter plot:  price vs bedrooms colored by interest_level ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# limit number of bedrooms and prices\nusable_train =  train[(train.price<10000) & (train.bedrooms<=4)]\npalette = {\"high\": \"r\", \"low\":\"g\", \"medium\":\"orange\"}\nplt.figure(figsize=(11,10))\nfor interest in ['low', 'medium', 'high']:\n    plt.scatter(usable_train[usable_train.interest_level==interest].bedrooms, \n                usable_train[usable_train.interest_level==interest].price, \n                c=palette[interest])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "High interest goes for low prices",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Boxplot gives even better insights ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(11,10))\nsns.boxplot(x=\"bedrooms\", y=\"price\", hue=\"interest_level\", data=usable_train, palette=palette)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## How can we use this ?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def add_median_price(key=None, suffix=\"\", trn_df=None, tst_df=None):\n    \"\"\"\n    Compute median prices for renthop dataset.\n    The function adds 2 columns to the pandas DataFrames : the median prices and a ratio\n    between nthe actual price of the rent and the median\n    \n    :param key: list of columns on which to groupby and compute median prices\n    :param suffix: string used to suffix the newly created columns/features\n    :param trn_df: training dataset as a pandas DataFrame\n    :param tst_df: test dataset as a pandas DataFrame\n    :return: updated train and test DataFrames\n\n    :Example\n    \n    train, test = add_median_price(key=['bedrooms', 'bathrooms'], \n                                   suffix='rooms', \n                                   trn_df=train, \n                                   tst_df=test)\n\n    \"\"\"\n    # Set features to be used\n    median_features = key.copy()\n    median_features.append('price')\n    # Concat train and test to find median prices over whole dataset\n    median_prices = pd.concat([trn_df[median_features], tst_df[median_features]], axis=0)\n    # Group data by key to compute median prices\n    medians_by_key = median_prices.groupby(by=key)['price'].median().reset_index()\n    # Rename median column with provided suffix\n    medians_by_key.rename(columns={'price': 'median_price_' + suffix}, inplace=True)\n    # Update data frames, note that merge seems to reset the index\n    # that's why I reset first and set again the index\n    trn_df = trn_df.reset_index().merge(medians_by_key, on=key, how='left').set_index('listing_id')\n    tst_df = tst_df.reset_index().merge(medians_by_key, on=key, how='left').set_index('listing_id')\n    trn_df['price_to_median_ratio_' + suffix] = trn_df['price'] /trn_df['median_price_' + suffix]\n    tst_df['price_to_median_ratio_' + suffix] = tst_df['price'] / tst_df['median_price_' + suffix]\n\n    return trn_df, tst_df",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Define classifier over 10 folds",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom xgboost import XGBClassifier\nimport time\n\ndef run_classifier():\n    n_folds = 3\n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=67594235)\n    train_features = [ f for f in train.columns \n                      if (train[f].dtype != 'object') & (f != 'interest_level') ]\n\n    target_num_map = {'high': 0, 'medium': 1, 'low': 2}\n    target = np.array(train['interest_level'].apply(lambda x: target_num_map[x]))\n\n    tst_scores = []\n    tst_rounds = []\n\n    data_X = train[train_features].values\n    start = time.time()\n    features_imp = np.zeros(len(train_features))\n    for fold, (trn_idx, tst_idx) in enumerate(skf.split(data_X, target)):\n        # Create a classifier\n        clf = XGBClassifier(n_estimators=10000,\n                            objective='multi:softprob',\n                            learning_rate=0.3,\n                            max_depth=3,\n                            min_child_weight=1,\n                            subsample=.8,\n                            colsample_bytree=.9,\n                            colsample_bylevel=.5,\n                            gamma=0.0005,\n                            scale_pos_weight=1,\n                            base_score=.5,\n                            reg_lambda=0,\n                            reg_alpha=0,\n                            missing=0,\n                            seed=0)\n\n        # Split the data\n        trn_X = data_X[trn_idx]\n        trn_Y = target[trn_idx]\n        tst_X = data_X[tst_idx]\n        tst_Y = target[tst_idx]\n\n        # Train the model\n        clf.fit(trn_X, trn_Y,\n            eval_set=[(trn_X, trn_Y), (tst_X, tst_Y)],\n            verbose=False,\n            eval_metric='mlogloss',\n            early_stopping_rounds=50)\n\n        # Get features importance\n        features_imp += clf.feature_importances_\n\n        # Predict the data\n        preds = clf.predict_proba(tst_X, ntree_limit=clf.best_ntree_limit)\n\n        tst_scores.append(log_loss(tst_Y, preds))\n        tst_rounds.append(clf.best_ntree_limit)\n    \n        print(\"LogLoss for fold %2d : %.5f\" % (fold+1, log_loss(tst_Y, preds)))\n\n    print(\"Average LogLoss : %.5f / %.6f in %4d rounds [%5.1f mn]\"\n          % (np.mean(tst_scores),\n             np.std(tst_scores),\n             np.mean(tst_rounds), (time.time() - start)/60))\n    \n    return train_features, features_imp",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Train with basic features",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for df in (train, test):\n    df['nb_images'] = df['photos'].apply(len)\n    df['nb_features'] = df['features'].apply(len)\n    df['nb_words'] = df['description'].apply(lambda x: len(x.split()))\n\ntrain_features, features_imp = run_classifier()\n                                             ",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Train with median price over bedrooms",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train, test = add_median_price(key=['bedrooms'],\n                               suffix=\"bed\",\n                               trn_df=train, tst_df=test)\n\ntrain_features, features_imp = run_classifier()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Show feature_importances",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "imp_df = pd.DataFrame(data={'feature': train_features, \n                            'importance': features_imp})\nimp_df.sort_values(by='importance', ascending=False, inplace=True)\nsns.barplot(x=\"importance\", y=\"feature\", data=imp_df)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}