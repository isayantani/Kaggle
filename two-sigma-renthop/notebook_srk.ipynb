{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "In this exploration notebook, we shall try to uncover the basic information about the dataset which will help us build our models / features. \n\nLet us first import the necessary modules.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  # default='warn'",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Loading the training dataset and looking at the top few rows.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df = pd.read_json(\"../input/train.json\")\ntrain_df.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Wow. This dataset looks interesting. It has numerical features, categorical features, date feature, text features and image features.  \n\nLet us load the test data as well and check the number of rows in train and test to start with.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_df = pd.read_json(\"../input/test.json\")\nprint(\"Train Rows : \", train_df.shape[0])\nprint(\"Test Rows : \", test_df.shape[0])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Target Variable**\n\nBefore delving more into the features, let us first have a look at the target variable 'interest level'",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "int_level = train_df['interest_level'].value_counts()\n\nplt.figure(figsize=(8,4))\nsns.barplot(int_level.index, int_level.values, alpha=0.8, color=color[1])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Interest level', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Interest level is low for most of the cases followed by medium and then high which makes sense.\n\nNow let us start looking into the numerical features present in the dataset. Numerical features are\n\n - bathrooms\n - bedrooms\n - price\n - latitude\n - longitude\n\nThe last two are actually not numerical variables, but for now let us just consider it to be numerical.\n\n**Bathrooms:**\n\nLet us first start with bathrooms.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cnt_srs = train_df['bathrooms'].value_counts()\n\nplt.figure(figsize=(8,4))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('bathrooms', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df['bathrooms'].ix[train_df['bathrooms']>3] = 3\nplt.figure(figsize=(8,4))\nsns.violinplot(x='interest_level', y='bathrooms', data=train_df)\nplt.xlabel('Interest level', fontsize=12)\nplt.ylabel('bathrooms', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Looks like evenly distributed across the interest levels. Now let us look at the next feature 'bedrooms'.\n\n**Bedrooms:**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cnt_srs = train_df['bedrooms'].value_counts()\n\nplt.figure(figsize=(8,4))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[2])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('bedrooms', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8,6))\nsns.countplot(x='bedrooms', hue='interest_level', data=train_df)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('bedrooms', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Price:**\n\nNow let us look at the price variable distribution.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.price.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Looks like there are some outliers in this feature. So let us remove them and then plot again.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ulimit = np.percentile(train_df.price.values, 99)\ntrain_df['price'].ix[train_df['price']>ulimit] = ulimit\n\nplt.figure(figsize=(8,6))\nsns.distplot(train_df.price.values, bins=50, kde=True)\nplt.xlabel('price', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The distribution is right skewed as we can see.\n\nNow let us look at the latitude and longitude variables.\n\n**Latitude & Longitude:**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "llimit = np.percentile(train_df.latitude.values, 1)\nulimit = np.percentile(train_df.latitude.values, 99)\ntrain_df['latitude'].ix[train_df['latitude']<llimit] = llimit\ntrain_df['latitude'].ix[train_df['latitude']>ulimit] = ulimit\n\nplt.figure(figsize=(8,6))\nsns.distplot(train_df.latitude.values, bins=50, kde=False)\nplt.xlabel('latitude', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "So the latitude values are primarily between 40.6 and 40.9. Now let us look at the longitude values.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "llimit = np.percentile(train_df.longitude.values, 1)\nulimit = np.percentile(train_df.longitude.values, 99)\ntrain_df['longitude'].ix[train_df['longitude']<llimit] = llimit\ntrain_df['longitude'].ix[train_df['longitude']>ulimit] = ulimit\n\nplt.figure(figsize=(8,6))\nsns.distplot(train_df.longitude.values, bins=50, kde=False)\nplt.xlabel('longitude', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The longitude values range between -73.8 and -74.02. So the data corresponds to the **New York City**.\n\nNow let us plot the same in a map. Thanks to this [kernel][1] by Dotman.\n\n\n  [1]: https://www.kaggle.com/dotman/d/fivethirtyeight/uber-pickups-in-new-york-city/data-exploration-and-visualization",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from mpl_toolkits.basemap import Basemap\nfrom matplotlib import cm\n\nwest, south, east, north = -74.02, 40.64, -73.85, 40.86\n\nfig = plt.figure(figsize=(14,10))\nax = fig.add_subplot(111)\nm = Basemap(projection='merc', llcrnrlat=south, urcrnrlat=north,\n            llcrnrlon=west, urcrnrlon=east, lat_ts=south, resolution='i')\nx, y = m(train_df['longitude'].values, train_df['latitude'].values)\nm.hexbin(x, y, gridsize=200,\n         bins='log', cmap=cm.YlOrRd_r);",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Created:**\n\nNow let us look at the date column 'created' ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\ntrain_df[\"date_created\"] = train_df[\"created\"].dt.date\ncnt_srs = train_df['date_created'].value_counts()\n\n\nplt.figure(figsize=(12,4))\nax = plt.subplot(111)\nax.bar(cnt_srs.index, cnt_srs.values, alpha=0.8)\nax.xaxis_date()\nplt.xticks(rotation='vertical')\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "So we have data from April to June 2016 in our train set. Now let us look at the test set as well and see if they are also from the same date range. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\ntest_df[\"date_created\"] = test_df[\"created\"].dt.date\ncnt_srs = test_df['date_created'].value_counts()\n\nplt.figure(figsize=(12,4))\nax = plt.subplot(111)\nax.bar(cnt_srs.index, cnt_srs.values, alpha=0.8)\nax.xaxis_date()\nplt.xticks(rotation='vertical')\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Looks very similar to the train set dates and so we are good to go.!\n\nWe shall also look at the hour-wise listing trend (Just for fun)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df[\"hour_created\"] = train_df[\"created\"].dt.hour\ncnt_srs = train_df['hour_created'].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[3])\nplt.xticks(rotation='vertical')\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Looks like listings are created during the early hours of the day (1 to 7am). May be that is when the traffic is less and so the updates are happening.\n\nNow let us look at some of the categorical variables.\n\n**Display Address:**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cnt_srs = train_df.groupby('display_address')['display_address'].count()\n\nfor i in [2, 10, 50, 100, 500]:\n    print('Display_address that appear less than {} times: {}%'.format(i, round((cnt_srs < i).mean() * 100, 2)))\n\nplt.figure(figsize=(12, 6))\nplt.hist(cnt_srs.values, bins=100, log=True, alpha=0.9)\nplt.xlabel('Number of times display_address appeared', fontsize=12)\nplt.ylabel('log(Count)', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Most of the display addresses occur less than 100 times in the given dataset. None of the display address occur more than 500 times.\n\n**Number of Photos:**\n\nThis competition also has a huge database of photos of the listings. To start with, let us look at the number of photos given for listings.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\ncnt_srs = train_df['num_photos'].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.xlabel('Number of Photos', fontsize=12)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df['num_photos'].ix[train_df['num_photos']>12] = 12\nplt.figure(figsize=(12,6))\nsns.violinplot(x=\"num_photos\", y=\"interest_level\", data=train_df, order =['low','medium','high'])\nplt.xlabel('Number of Photos', fontsize=12)\nplt.ylabel('Interest Level', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let us now look at the number of features variable and see its distribution.\n\n**Number of features:**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\ncnt_srs = train_df['num_features'].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of features', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df['num_features'].ix[train_df['num_features']>17] = 17\nplt.figure(figsize=(12,10))\nsns.violinplot(y=\"num_features\", x=\"interest_level\", data=train_df, order =['low','medium','high'])\nplt.xlabel('Interest Level', fontsize=12)\nplt.ylabel('Number of features', fontsize=12)\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Word Clouds:**\n\nNext we shall look into some for the text features.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from wordcloud import WordCloud\n\ntext = ''\ntext_da = ''\ntext_desc = ''\nfor ind, row in train_df.iterrows():\n    for feature in row['features']:\n        text = \" \".join([text, \"_\".join(feature.strip().split(\" \"))])\n    text_da = \" \".join([text_da,\"_\".join(row['display_address'].strip().split(\" \"))])\n    #text_desc = \" \".join([text_desc, row['description']])\ntext = text.strip()\ntext_da = text_da.strip()\ntext_desc = text_desc.strip()\n\nplt.figure(figsize=(12,6))\nwordcloud = WordCloud(background_color='white', width=600, height=300, max_font_size=50, max_words=40).generate(text)\nwordcloud.recolor(random_state=0)\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for features\", fontsize=30)\nplt.axis(\"off\")\nplt.show()\n\n# wordcloud for display address\nplt.figure(figsize=(12,6))\nwordcloud = WordCloud(background_color='white', width=600, height=300, max_font_size=50, max_words=40).generate(text_da)\nwordcloud.recolor(random_state=0)\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for Display Address\", fontsize=30)\nplt.axis(\"off\")\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**More to come. Stay tuned.!**\n\nPlease upvote if you like the notebook :)",
      "metadata": {}
    }
  ]
}